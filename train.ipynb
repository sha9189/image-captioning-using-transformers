{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599804946593",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from models import utils, caption\n",
    "import spacy\n",
    "spacy_eng = spacy.load(\"en\")\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "from datasets import coco\n",
    "from configuration import Config\n",
    "from engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    device = torch.device(config.device)\n",
    "    print(f'Initializing Device: {device}')\n",
    "\n",
    "    seed = config.seed + utils.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    model, criterion = caption.build_model(config)\n",
    "    model.to(device)\n",
    "\n",
    "    n_parameters = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Number of params: {n_parameters}\")\n",
    "\n",
    "    param_dicts = [\n",
    "        {\"params\": [p for n, p in model.named_parameters(\n",
    "        ) if \"backbone\" not in n and p.requires_grad]},\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "            \"lr\": config.lr_backbone,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        param_dicts, lr=config.lr, weight_decay=config.weight_decay)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, config.lr_drop)\n",
    "\n",
    "    dataset_train = coco.build_dataset(config, mode='training')\n",
    "    dataset_val = coco.build_dataset(config, mode='validation')\n",
    "    print(f\"Train: {len(dataset_train)}\")\n",
    "    print(f\"Valid: {len(dataset_val)}\")\n",
    "\n",
    "    sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "    sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "    batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "        sampler_train, config.batch_size, drop_last=True\n",
    "    )\n",
    "\n",
    "    data_loader_train = DataLoader(\n",
    "        dataset_train, batch_sampler=batch_sampler_train, num_workers=config.num_workers)\n",
    "    data_loader_val = DataLoader(dataset_val, config.batch_size,\n",
    "                                 sampler=sampler_val, drop_last=False, num_workers=config.num_workers)\n",
    "\n",
    "    if os.path.exists(config.checkpoint):\n",
    "        print(\"Loading Checkpoint...\")\n",
    "        checkpoint = torch.load(config.checkpoint, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "        config.start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "    print(\"Start Training..\")\n",
    "    for epoch in range(config.start_epoch, config.epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        epoch_loss = train_one_epoch(\n",
    "            model, criterion, data_loader_train, optimizer, device, epoch, config.clip_max_norm)\n",
    "        lr_scheduler.step()\n",
    "        print(f\"Training Loss: {epoch_loss}\")\n",
    "\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "        }, config.checkpoint)\n",
    "\n",
    "        validation_loss = evaluate(model, criterion, data_loader_val, device)\n",
    "        print(f\"Validation Loss: {validation_loss}\")\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from configuration import Config\n",
    "config=Config()\n",
    "# main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.utils import read_json\n",
    "import re\n",
    "file_name = os.path.join(config.dir, 'annotations', 'captions_val2017.json')\n",
    "ann = read_json(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process(image_id):\n",
    "    val = str(image_id).zfill(12)\n",
    "    return val + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = [(_process(val['image_id']), re.sub(' +', ' ', val['caption'].replace(\".\", \" \").replace(\",\", \" \").replace(\":\", \" \"))) for val in ann['annotations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('000000179765.jpg', 'A black Honda motorcycle parked in front of a garage ')"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "annot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_words = ['bedroom', 'room', 'table', 'chair', 'recliner', 'pillow', 'cupboard', 'wardrobe', 'dining', 'sofa', 'kitchen', 'clock', 'tv', 'television', 'curtain', 'telephone', 'kitchen', 'fan', 'lamp', 'carpet', 'beanbag', 'fireplace', 'book', 'bookshelf', 'speaker', 'drape', 'plant', 'pot', 'desk', 'mirror', 'bulb', 'fridge', 'refrigerator', 'bathroom']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "annot_txt = open(\"val_captions.txt\", \"w\")\n",
    "for id, caption in annot:\n",
    "    # if any room_word is present in caption, write it in the file\n",
    "    for word in room_words:\n",
    "        if word in caption:\n",
    "            line = id+ \"\\t\"+  caption\n",
    "            annot_txt.write(line + \"\\n\")\n",
    "            break\n",
    "annot_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the file containing all caption-image pairs\n",
    "with open('train_captions.txt', 'r') as file:\n",
    "    annotations = file.read()\n",
    "\n",
    "# Store captions and image names in vectors\n",
    "all_captions = []\n",
    "all_imgs = []\n",
    "\n",
    "# splitting the file contents by line\n",
    "for annot in annotations.split(\"\\n\"):\n",
    "        # Skip empty lines\n",
    "        if len(annot)<1:\n",
    "            continue\n",
    "        caption = annot.split()[1:]\n",
    "        try:\n",
    "            image_id = annot.split()[0]\n",
    "        except:\n",
    "            print(image_id, \":\", caption)\n",
    "\n",
    "        all_imgs.append(image_id)\n",
    "        all_captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "40054"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "train_ids = sorted(set(all_imgs))\n",
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1711"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# Read the file containing all caption-image pairs\n",
    "with open('val_captions.txt', 'r') as file:\n",
    "    annotations = file.read()\n",
    "\n",
    "# Store captions and image names in vectors\n",
    "all_captions = []\n",
    "all_imgs = []\n",
    "\n",
    "# splitting the file contents by line\n",
    "for annot in annotations.split(\"\\n\"):\n",
    "        # Skip empty lines\n",
    "        if len(annot)<1:\n",
    "            continue\n",
    "        caption = annot.split()[1:]\n",
    "        try:\n",
    "            image_id = annot.split()[0]\n",
    "        except:\n",
    "            print(image_id, \":\", caption)\n",
    "\n",
    "        all_imgs.append(image_id)\n",
    "        all_captions.append(caption)\n",
    "\n",
    "val_ids = sorted(set(all_imgs))\n",
    "len(val_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- **121508 image caption pairs** for training set with 40054 unique images.\n",
    "- **5090 image caption** pairs for validation set with 1711 unique images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from torchtext.data import Field\n",
    "import torch\n",
    "import numpy as np\n",
    "from configuration import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = \"The room has a sofa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "13838"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Read the file containing all caption-image pairs\n",
    "with open('train_captions.txt', 'r') as file:\n",
    "    annotations = file.read()\n",
    "\n",
    "# Store captions and image names in vectors\n",
    "all_words = []\n",
    "\n",
    "# splitting the file contents by line\n",
    "for annot in annotations.split(\"\\n\"):\n",
    "        # Skip empty lines\n",
    "        if len(annot)<1:\n",
    "            continue\n",
    "        caption = annot.split()[1:]\n",
    "        caption = \" \".join(caption)\n",
    "        caption = english.tokenize(caption)\n",
    "        all_words += caption \n",
    "\n",
    "all_words = list(set(all_words))\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en\")\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "13842"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "english.build_vocab([all_words])\n",
    "len(english.vocab.stoi.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(english, \"english.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "english = torch.load('english.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = english.tokenize(\"Hello this is shailesh's phone\")\n",
    "tokens = ['<sos>'] + tokens + ['<eos>']\n",
    "numbs = english.numericalize([tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(['<sos>', 'Hello', 'this', 'is', 'shailesh', \"'s\", 'phone', '<eos>'],\n tensor([[    2,  1151, 12635,  7719,     0,    13,  9728,     3]]))"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "tokens, numbs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([    2,  1151, 12635,  7719,     0,    13,  9728,     3])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "toks = numbs.numpy().T[0]\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2.0000e+00, 1.1510e+03, 1.2635e+04, 7.7190e+03, 0.0000e+00,\n       1.3000e+01, 9.7280e+03, 3.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "config=Config()\n",
    "caption = np.zeros(config.max_position_embeddings)\n",
    "caption[:len(toks)] = toks\n",
    "caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'<sos>'"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "english.vocab.itos[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "cap_mask = np.ones(config.max_position_embeddings)\n",
    "cap_mask[:len(toks)] = 0\n",
    "cap_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to successfully run coco.build_dataset\n",
    "import spacy\n",
    "from configuration import Config\n",
    "from datasets import coco\n",
    "\n",
    "config = Config()\n",
    "spacy_eng = spacy.load(\"en\")\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "data = coco.build_dataset(config, mode=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask, caption, cap_mask = data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "cap_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using cache found in /home/shailesh/.cache/torch/hub/facebookresearch_detr_master\n"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.backbone.state_dict(), \"pretrained_wts/backbone.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from models import utils, caption\n",
    "import spacy\n",
    "spacy_eng = spacy.load(\"en\")\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "from datasets import coco\n",
    "from configuration import Config\n",
    "from engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model, _ = caption.build_model(config=Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "my_model.backbone.load_state_dict(torch.load(\"pretrained_wts/backbone.pth\"), strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using cache found in /home/shailesh/.cache/torch/hub/saahiluppal_catr_master\n"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('saahiluppal/catr', 'v2', pretrained=True)\n",
    "# Use V2 for sine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.transformer.encoder.state_dict(), \"pretrained_wts/trans-encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.transformer.decoder.state_dict(), \"pretrained_wts/trans-decoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.mlp.layers[0].state_dict(), \"pretrained_wts/mlp-layer0.pth\")\n",
    "torch.save(model.mlp.layers[1].state_dict(), \"pretrained_wts/mlp-layer1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "(model.mlp.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "my_model.backbone.load_state_dict(torch.load(\"pretrained_wts/others/backbone.pth\"), strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "my_model.transformer.encoder.load_state_dict(torch.load(\"pretrained_wts/others/trans-encoder.pth\"), strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "my_model.transformer.decoder.load_state_dict(torch.load(\"pretrained_wts/others/trans-decoder.pth\"), strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "my_model.load_state_dict(torch.load(\"pretrained_wts/my_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "my_model.mlp.layers[0].load_state_dict(torch.load(\"pretrained_wts/mlp-layer0.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "my_model.mlp.layers[1].load_state_dict(torch.load(\"pretrained_wts/mlp-layer1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_model.state_dict(), \"pretrained_wts/my_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"val_captions.txt\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(text.split(\"\\n\")):\n",
    "    if \".jpg\" not in line:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################\n",
    "# Model checkpointing notes:\n",
    "# 1. Manually look for the latest models/\n",
    "# 2. Set the model number in (\"Loading Checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_captions.txt\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest=0\n",
    "for line in text.split('\\n'):\n",
    "    caption = line.split()[1:]\n",
    "    caption = \" \".join(caption)\n",
    "    caption = english.tokenize(caption)\n",
    "    caption = ['<sos>'] + caption + ['<eos>']\n",
    "    longest = max(len(caption), longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "52"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "49"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "tokens = english.tokenize(\"Hello this is shailesh's phone\")\n",
    "tokens = ['<sos>'] + tokens + ['<eos>']\n",
    "numbs = english.numericalize([tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from models import utils, caption\n",
    "from configuration import Config\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "import spacy\n",
    "spacy_eng = spacy.load(\"en\")\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "from datasets import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initializing Device: cuda\nModel Loaded\nNumber of params: 52173842\nTrain: 121086\nValid: 5073\nLoading Checkpoint...\n"
    }
   ],
   "source": [
    "device = torch.device(config.device)\n",
    "print(f'Initializing Device: {device}')\n",
    "seed = config.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "model, criterion = caption.build_model(config)\n",
    "model.load_state_dict(torch.load(\"pretrained_wts/my_model.pth\"))\n",
    "model.to(device)\n",
    "print(\"Model Loaded\")\n",
    "n_parameters = sum(p.numel()\n",
    "                   for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of params: {n_parameters}\")\n",
    "param_dicts = [\n",
    "    {\"params\": [p for n, p in model.named_parameters(\n",
    "    ) if \"backbone\" not in n and p.requires_grad]},\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "        \"lr\": config.lr_backbone,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(\n",
    "    param_dicts, lr=config.lr, weight_decay=config.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, config.lr_drop)\n",
    "    \n",
    "dataset_train = coco.build_dataset(config, mode='training')\n",
    "dataset_val = coco.build_dataset(config, mode='validation')\n",
    "print(f\"Train: {len(dataset_train)}\")\n",
    "print(f\"Valid: {len(dataset_val)}\")\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "    sampler_train, config.batch_size, drop_last=True\n",
    ")\n",
    "data_loader_train = DataLoader(\n",
    "    dataset_train, batch_sampler=batch_sampler_train, num_workers=config.num_workers)\n",
    "data_loader_val = DataLoader(dataset_val, config.batch_size,\n",
    "                             sampler=sampler_val, drop_last=False, num_workers=config.num_workers)\n",
    "if os.path.exists(config.checkpoint + \"12\"):\n",
    "    print(\"Loading Checkpoint...\")\n",
    "    checkpoint = torch.load(config.checkpoint + \"12\", map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    config.start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded Checkpoint: ./checkpoints/checkpoint.pth12\n"
    }
   ],
   "source": [
    "print(\"Loaded Checkpoint:\", config.checkpoint + \"12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}